@preprint{dillavou_bellybutton_2023,
  title = {Bellybutton: {{Accessible}} and {{Customizable Deep-Learning Image Segmentation}}},
  shorttitle = {Bellybutton},
  author = {Dillavou, Sam and Hanlan, Jesse M. and Chieco, Anthony T. and Xiao, Hongyi and Fulco, Sage and Turner, Kevin T. and Durian, Douglas J.},
  year = {2023},
  month = aug,
  number = {arXiv:2309.00058},
  arxiv = {2309.00058},
  primaryclass = {cond-mat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.00058},
  urldate = {2023-09-05},
  abstract = {The conversion of raw images into quantifiable data can be a major hurdle in experimental research, and typically involves identifying region(s) of interest, a process known as segmentation. Machine learning tools for image segmentation are often specific to a set of tasks, such as tracking cells, or require substantial compute or coding knowledge to train and use. Here we introduce an easy-to-use (no coding required), image segmentation method, using a 15-layer convolutional neural network that can be trained on a laptop: Bellybutton. The algorithm trains on user-provided segmentation of example images, but, as we show, just one or even a portion of one training image can be sufficient in some cases. We detail the machine learning method and give three use cases where Bellybutton correctly segments images despite substantial lighting, shape, size, focus, and/or structure variation across the regions(s) of interest. Instructions for easy download and use, with further details and the datasets used in this paper are available at pypi.org/project/Bellybuttonseg.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Condensed Matter - Soft Condensed Matter},
  file = {/Users/Sam_1/Zotero/storage/JBDQWK6Y/Dillavou et al. - 2023 - Bellybutton Accessible and Customizable Deep-Lear.pdf;/Users/Sam_1/Zotero/storage/ZJYLGQIZ/2309.html},
  preview = {2023Bellybutton.jpg}
}

@inproceedings{dillavou_circuits_2023,
  title = {Circuits That Train Themselves: Decentralized, Physics-Driven Learning},
  shorttitle = {Circuits That Train Themselves},
  booktitle = {{{AI}} and {{Optical Data Sciences IV}}},
  author = {Dillavou, Sam and Beyer, Benjamin and Stern, Menachem and Miskin, Marc Z. and Liu, Andrea J. and Durian, Douglas J.},
  year = {2023},
  month = mar,
  volume = {12438},
  pages = {115--117},
  publisher = {SPIE},
  doi = {10.1117/12.2648618},
  urldate = {2023-09-29},
  abstract = {In typical artificial neural networks, neurons adjust according to global calculations of a central processor, but in the brain neurons and synapses self-adjust based on local information. A man-made self-adjusting (distributed) system capable of performing machine-learning problems would have substantial scaling advantages over typical computational neural networks, in power consumption, speed, and robustness to damage. Furthermore, such a system would allow us to study physical learning without the added complexity of biology. Here we unveil the second-generation design of such a system -- a transistor-based self-adjusting analog network that trains itself to perform a wide variety of tasks. Here we demonstrate basic features of the system, including the ability to monitor all internal states. This platform is already faster than a simulation of itself, and is thus an exciting platform for the investigation of physical learning.}
}

@article{dillavou_demonstration_2022,
  title = {Demonstration of {{Decentralized Physics-Driven Learning}}},
  author = {Dillavou, Sam and Stern, Menachem and Liu, Andrea J. and Durian, Douglas J.},
  year = {2022},
  month = jul,
  journal = {Physical Review Applied},
  volume = {18},
  number = {1},
  pages = {014040},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevApplied.18.014040},
  urldate = {2022-07-19},
  abstract = {In typical artificial neural networks, neurons adjust according to global calculations of a central processor, but in the brain, neurons and synapses self-adjust based on local information. Contrastive learning algorithms have recently been proposed to train physical systems, such as fluidic, mechanical, or electrical networks, to perform machine-learning tasks from local evolution rules. However, to date, such systems have only been implemented in silico due to the engineering challenge of creating elements that autonomously evolve based on their own response to two sets of global boundary conditions. Here, we introduce and implement a physics-driven contrastive learning scheme for a network of variable resistors, using circuitry to locally compare the response of two identical networks subjected to the two different sets of boundary conditions. Using this method, our system effectively trains itself, optimizing its resistance values without the use of a central processor or external information storage. Once the system is trained for a specified allostery, regression, or classification task, the task is subsequently performed rapidly and automatically by the physical imperative to minimize power dissipation in response to the given voltage inputs. We demonstrate that, unlike typical computers, such learning systems are robust to extreme damage (and thus manufacturing defects) due to their decentralized learning. Our twin-network approach is therefore readily scalable to extremely large or nonlinear networks, where its distributed nature will be an enormous advantage; a laboratory network of only 500 edges will already outpace its in silico counterpart.},
  file = {/Users/Sam_1/Zotero/storage/V8NLN9FD/Dillavou et al. - 2022 - Demonstration of Decentralized Physics-Driven Lear.pdf;/Users/Sam_1/Zotero/storage/Q38WUMVL/PhysRevApplied.18.html},
  arxiv = {2108.00275}
}

@preprint{dillavou_machine_2023,
  title = {Machine {{Learning Without}} a {{Processor}}: {{Emergent Learning}} in a {{Nonlinear Electronic Metamaterial}}},
  shorttitle = {Machine {{Learning Without}} a {{Processor}}},
  author = {Dillavou, Sam and Beyer, Benjamin D. and Stern, Menachem and Miskin, Marc Z. and Liu, Andrea J. and Durian, Douglas J.},
  year = {2023},
  month = nov,
  number = {arXiv:2311.00537},
  arxiv = {2311.00537},
  primaryclass = {cond-mat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.00537},
  urldate = {2024-02-20},
  abstract = {Standard deep learning algorithms require differentiating large nonlinear networks, a process that is slow and power-hungry. Electronic learning metamaterials offer potentially fast, efficient, and fault-tolerant hardware for analog machine learning, but existing implementations are linear, severely limiting their capabilities. These systems differ significantly from artificial neural networks as well as the brain, so the feasibility and utility of incorporating nonlinear elements have not been explored. Here we introduce a nonlinear learning metamaterial -- an analog electronic network made of self-adjusting nonlinear resistive elements based on transistors. We demonstrate that the system learns tasks unachievable in linear systems, including XOR and nonlinear regression, without a computer. We find our nonlinear learning metamaterial reduces modes of training error in order (mean, slope, curvature), similar to spectral bias in artificial neural networks. The circuitry is robust to damage, retrainable in seconds, and performs learned tasks in microseconds while dissipating only picojoules of energy across each transistor. This suggests enormous potential for fast, low-power computing in edge systems like sensors, robotic controllers, and medical devices, as well as manufacturability at scale for performing and studying emergent learning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Emerging Technologies,Computer Science - Machine Learning,Condensed Matter - Soft Condensed Matter},
  file = {/Users/Sam_1/Zotero/storage/W3PLLE48/Dillavou et al. - 2023 - Machine Learning Without a Processor Emergent Lea.pdf;/Users/Sam_1/Zotero/storage/4XQW99SW/2311.html},
  preview = {2023NonlinearNetwork.jpg}
}


spatt

@article{durian_spatters_2022,
  title = {Spatters and Spills: {{Spreading}} Dynamics for Partially Wetting Droplets},
  shorttitle = {Spatters and Spills},
  author = {Durian, Sylvia C. L. and Dillavou, Sam and Markin, Kwame and Portales, Adrian and Maldonado, Bryan O. Torres and Irvine, William T. M. and Arratia, Paulo E. and Durian, Douglas J.},
  date = {2022-01},
  year = {2022},
  journal = {Physics of Fluids},
  volume = {34},
  number = {1},
  pages = {012112},
  issn = {1070-6631, 1089-7666},
  doi = {10.1063/5.0077461},
  url = {https://aip.scitation.org/doi/10.1063/5.0077461},
  urldate = {2022-01-11},
  abstract = {We present a solvable model inspired by dimensional analysis for the time-dependent spreading of droplets that partially wet a substrate, where the spreading eventually stops and the contact angle reaches a nonzero equilibrium value. We separately consider small droplets driven by capillarity and large droplets driven by gravity. To explore both regimes, we first measure the equilibrium radius vs a comprehensive range of droplet volumes for four household fluids, and we compare the results with predictions based on minimizing the sum of gravitational and interfacial energies. The agreement is good and gives a reliable measurement of an equilibrium contact angle that is consistent in both small and large droplet regimes. Next, we use energy considerations to develop equations of motion for the time dependence of the spreading, in both regimes, where the driving forces are balanced against viscous drag in the bulk of the droplet and by friction at the moving contact line. Our approach leads to explicit prediction of the functional form of the spreading dynamics. It successfully describes prior data for a small capillary-driven droplet, and it fits well to new data we obtain for large gravity-driven droplets with a wide range of volumes. While our prediction for the dynamics of small capillary-driven droplets assumes the case of thin nearly wetting droplets, with a small contact angle, this restriction is not otherwise invoked.},
  langid = {english},
  file = {/Users/Sam_1/Zotero/storage/8J88BAXW/Durian et al. - 2022 - Spatters and spills Spreading dynamics for partia.pdf},
}

@preprint{gerra_equation_2024,
  title = {The {{Equation}} of {{Motion}} for {{Taut-Line Buzzers}}},
  author = {Gerra, Alexander J. and Jones, Courtney C. and Dillavou, Sam and Hanlan, Jesse M. and Radzio, Julia and Arratia, Paulo E. and Durian, Douglas J.},
  date = {2024-02-29},
  eprint = {2402.19285},
  month = feb,
  eprinttype = {arxiv},
  eprintclass = {cond-mat},
  doi = {10.48550/arXiv.2402.19285},
  url = {http://arxiv.org/abs/2402.19285},
  urldate = {2024-04-15},
  abstract = {Equations of motion are developed for the oscillatory rotation of a disk suspended between twisted strings kept under tension by a hanging mass, to which additional forces may be applied. In the absence of forcing, damped harmonic oscillations are observed to decay with an exponential time envelope for two different string types. This is consistent with damping caused by string viscosity, rather than air turbulence, and may be quantified in terms of a quality factor. To test the proposed equation of motion and model for viscous damping within the string, we measure both the natural oscillation frequency and the quality factor for widely varied values of string length, string radius, disk moment of inertia, and hanging mass. The data are found to scale in good accord with predictions. A variation where rotational kinetic energy is converted back and forth to spring potential energy is also discussed.},
  pubstate = {preprint},
  keywords = {Condensed Matter - Soft Condensed Matter},
  file = {/Users/Sam_1/Zotero/storage/8VBQAEP9/Gerra et al. - 2024 - The Equation of Motion for Taut-Line Buzzers.pdf;/Users/Sam_1/Zotero/storage/ZTJQGMPM/2402.html},
  arxiv = {2402.19285},
  preview = {2024Buzzers.jpg}
}

@preprint{hathcock_stochastic_2023,
  title = {Stochastic Dynamics of Granular Hopper Flows: A Slow Hidden Mode Controls the Stability of Clogs},
  shorttitle = {Stochastic Dynamics of Granular Hopper Flows},
  author = {Hathcock, David and Dillavou, Sam and Hanlan, Jesse M. and Durian, Douglas J. and Tu, Yuhai},
  date = {2023-12-02},
  month = dec,
  eprint = {2312.01194},
  eprinttype = {arxiv},
  eprintclass = {cond-mat},
  doi = {10.48550/arXiv.2312.01194},
  url = {http://arxiv.org/abs/2312.01194},
  urldate = {2024-04-15},
  abstract = {Granular flows in small-outlet hoppers exhibit intermittent clogging behavior: while a temporary clog (pause) can last for an extended period before flow spontaneously restarts, there are also permanent clogs that last beyond experimental timescales. Here, we introduce a phenomenological model with multiplicative noise that provides a dynamical explanation for these extreme events: they arise due to coupling between the flow rate and a slow hidden mode that controls the stability of clogs. The theory fully resolves the statistics of pause and clog events, including the non-exponential clogging times and non-Gaussian flow rate distribution and explains the stretched-exponential growth of the average clogging time with outlet size. Our work provides a framework for extracting features of granular flow dynamics from experimental trajectories.},
  pubstate = {preprint},
  keywords = {Condensed Matter - Soft Condensed Matter,Condensed Matter - Statistical Mechanics},
  file = {/Users/Sam_1/Zotero/storage/XTW9Y329/Hathcock et al. - 2023 - Stochastic dynamics of granular hopper flows a sl.pdf;/Users/Sam_1/Zotero/storage/4IXS7R74/2312.html},
  arxiv = {2312.01194},
  preview = {2024CloggingPhenom.jpg}
}



@inproceedings{dillavou_nonlinear_2023,
  title = {Nonlinear {{Classification Without}} a {{Processor}}},
  booktitle = {{{NeurIPS Workshop Machine Learning}} with {{New Compute Paradigms}}},
  author = {Dillavou, Sam and Beyer, Benjamin and Stern, Menachem and Miskin, Marc and Liu, Andrea and Durian, Douglas},
  year = {2023},
  month = dec,
  urldate = {2024-02-15},
  abstract = {Computers, as well as most neuromorphic hardware systems, use central processing and top-down algorithmic control to train for machine learning tasks. In contrast, brains are ensembles of 100 billion neurons working in tandem, giving them tremendous advantages in power efficiency and speed. Many physical systems `learn' through history dependence, but training a physical system to perform arbitrary nonlinear tasks without a processor has not been possible. Here we demonstrate the successful implementation of such a system - a learning meta-material. This nonlinear analog circuit is comprised of identical copies of a single simple element, each following the same local update rule. By applying voltages to our system (inputs), inference is performed by physics in microseconds. When labels are properly enforced (also via voltages), the system's internal state evolves in time, approximating gradient descent. Our system \${\textbackslash}textit\{learns on its own\}\$; it requires no processor. Once trained, it performs inference passively, requiring approximately 100{\textasciitilde}\${\textbackslash}mu\$W of total power dissipation across its edges. We demonstrate the flexibility and power efficiency of our system by solving nonlinear 2D classification tasks. Learning meta-materials have immense potential as fast, efficient, robust learning systems for edge computing, from smart sensors to medical devices to robotic control.},
  langid = {english},
  file = {/Users/Sam_1/Zotero/storage/39XR8AN3/Dillavou et al. - 2023 - Nonlinear Classification Without a Processor.pdf},
  preview = {2023Classification.jpg},
  pdf = {NonlinearClassificationWithoutAProcessor.pdf},
  html = {https://openreview.net/forum?id=4P65OwisG9}
}

@article{dillavou_nonmonotonic_2018,
  title = {Nonmonotonic {{Aging}} and {{Memory}} in a {{Frictional Interface}}},
  author = {Dillavou, Sam and Rubinstein, Shmuel M.},
  year = {2018},
  month = jun,
  journal = {Physical Review Letters},
  volume = {120},
  number = {22},
  pages = {224101},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.120.224101},
  urldate = {2021-04-21},
  abstract = {We measure the static frictional resistance and the real area of contact between two solid blocks subjected to a normal load. We show that following a two-step change in the normal load the system exhibits nonmonotonic aging and memory effects, two hallmarks of glassy dynamics. These dynamics are strongly influenced by the discrete geometry of the frictional interface, characterized by the attachment and detachment of unique microcontacts. The results are in good agreement with a theoretical model we propose that incorporates this geometry into the framework recently used to describe Kovacs-like relaxation in glasses as well as thermal disordered systems. These results indicate that a frictional interface is a glassy system and strengthen the notion that nonmonotonic relaxation behavior is generic in such systems.},
  file = {/Users/Sam_1/Zotero/storage/83IYEPSR/Dillavou and Rubinstein - 2018 - Nonmonotonic Aging and Memory in a Frictional Inte.pdf;/Users/Sam_1/Zotero/storage/6JC6HHXD/PhysRevLett.120.html},
  preview = {2018Friction.jpg}
}

@article{dillavou_quality_2022,
  title = {Beyond Quality and Quantity: {{Spatial}} Distribution of Contact Encodes Frictional Strength},
  shorttitle = {Beyond Quality and Quantity},
  author = {Dillavou, Sam and {Bar-Sinai}, Yohai and Brenner, Michael P. and Rubinstein, Shmuel M.},
  year = {2022},
  month = sep,
  journal = {Physical Review E},
  volume = {106},
  number = {3},
  pages = {L033001},
  issn = {2470-0045, 2470-0053},
  doi = {10.1103/PhysRevE.106.L033001},
  urldate = {2022-09-06},
  langid = {english},
  file = {/Users/Sam_1/Zotero/storage/5HUYJMQM/Dillavou et al. - 2022 - Beyond quality and quantity Spatial distribution .pdf},
  arxiv = {2006.15174}
}

@article{dillavou_shear_2020,
  title = {Shear {{Controls Frictional Aging}} by {{Erasing Memory}}},
  author = {Dillavou, Sam and Rubinstein, Shmuel M.},
  year = {2020},
  month = feb,
  journal = {Physical Review Letters},
  volume = {124},
  number = {8},
  pages = {085502},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.124.085502},
  urldate = {2021-04-21},
  abstract = {We simultaneously measure the static friction and the real area of contact between two solid bodies. These quantities are traditionally considered equivalent, and under static conditions both increase logarithmically in time, a phenomenon coined aging. Here we show that the frictional aging rate is determined by the combination of the aging rate of the real area of contact and two memory-erasure effects that occur when shear is changed (e.g., to measure static friction.) The application of a static shear load accelerates frictional aging while the aging rate of the real area of contact is unaffected. Moreover, a negative static shear---pulling instead of pushing---slows frictional aging, but similarly does not affect the aging of contacts. The origin of this shear effect on aging is geometrical. When shear load is increased, minute relative tilts between the two blocks prematurely erase interfacial memory prior to sliding, negating the effect of aging. Modifying the loading point of the interface eliminates these tilts and as a result frictional aging rate becomes insensitive to shear. We also identify a secondary memory-erasure effect that remains even when all tilts are eliminated and show that this effect can be leveraged to accelerate aging by cycling between two static shear loads.},
  file = {/Users/Sam_1/Zotero/storage/25MGTEZA/Dillavou and Rubinstein - 2020 - Shear Controls Frictional Aging by Erasing Memory.pdf;/Users/Sam_1/Zotero/storage/VEC36SCY/PhysRevLett.124.html},
  preview = {2019Friction.jpg}
}

@article{dillavou_virtual_2019,
  title = {The Virtual Frame Technique: Ultrafast Imaging with Any Camera},
  shorttitle = {The Virtual Frame Technique},
  author = {Dillavou, Sam and Rubinstein, Shmuel M. and Kolinski, John M.},
  year = {2019},
  month = mar,
  journal = {Optics Express},
  volume = {27},
  number = {6},
  pages = {8112--8120},
  publisher = {Optical Society of America},
  issn = {1094-4087},
  doi = {10.1364/OE.27.008112},
  urldate = {2021-04-21},
  abstract = {Many phenomena of interest in nature and industry occur rapidly and are difficult and cost-prohibitive to visualize properly without specialized cameras. Here we describe in detail the virtual frame technique (VFT), a simple, useful, and accessible mode of imaging that increases the frame acquisition rate of any camera by several orders of magnitude by leveraging its dynamic range. The VFT is a powerful tool for capturing rapid phenomena where the dynamics facilitate a transition between two states, and are thus binary. The advantages of the VFT are demonstrated by examining such dynamics in five physical processes at unprecedented rates and spatial resolution: fracture of an elastic solid, wetting of a solid surface, rapid fingerprint reading, peeling of adhesive tape, and impact of an elastic hemisphere on a hard surface. We show that the performance of the VFT exceeds that of any commercial high-speed camera not only in rate of imaging but also in field of view, achieving a 65MHz frame rate at 4MPx resolution. Finally, we discuss the performance of the VFT with several commercially available conventional and high-speed cameras. In principle, modern cell phones can achieve imaging rates of over a million frames per second using the VFT.},
  copyright = {\&\#169; 2019 Optical Society of America},
  langid = {english},
  file = {/Users/Sam_1/Zotero/storage/XUVLZUB9/Dillavou et al. - 2019 - The virtual frame technique ultrafast imaging wit.pdf;/Users/Sam_1/Zotero/storage/8JGTYYHM/fulltext.html},
  preview = {2019VFT.jpg}
}

@article{durian_spatters_2022,
  title = {Spatters and Spills: {{Spreading}} Dynamics for Partially Wetting Droplets},
  shorttitle = {Spatters and Spills},
  author = {Durian, Sylvia C. L. and Dillavou, Sam and Markin, Kwame and Portales, Adrian and Maldonado, Bryan O. Torres and Irvine, William T. M. and Arratia, Paulo E. and Durian, Douglas J.},
  year = {2022},
  month = jan,
  journal = {Physics of Fluids},
  volume = {34},
  number = {1},
  pages = {012112},
  issn = {1070-6631, 1089-7666},
  doi = {10.1063/5.0077461},
  urldate = {2022-01-11},
  abstract = {We present a solvable model inspired by dimensional analysis for the time-dependent spreading of droplets that partially wet a substrate, where the spreading eventually stops and the contact angle reaches a nonzero equilibrium value. We separately consider small droplets driven by capillarity and large droplets driven by gravity. To explore both regimes, we first measure the equilibrium radius vs a comprehensive range of droplet volumes for four household fluids, and we compare the results with predictions based on minimizing the sum of gravitational and interfacial energies. The agreement is good and gives a reliable measurement of an equilibrium contact angle that is consistent in both small and large droplet regimes. Next, we use energy considerations to develop equations of motion for the time dependence of the spreading, in both regimes, where the driving forces are balanced against viscous drag in the bulk of the droplet and by friction at the moving contact line. Our approach leads to explicit prediction of the functional form of the spreading dynamics. It successfully describes prior data for a small capillary-driven droplet, and it fits well to new data we obtain for large gravity-driven droplets with a wide range of volumes. While our prediction for the dynamics of small capillary-driven droplets assumes the case of thin nearly wetting droplets, with a small contact angle, this restriction is not otherwise invoked.},
  langid = {english},
  file = {/Users/Sam_1/Zotero/storage/8J88BAXW/Durian et al. - 2022 - Spatters and spills Spreading dynamics for partia.pdf}
}

@article{martin_calculations_2024,
  title = {Calculations without Math: ``{{Smart}} Instruments'' and the Transposition of Complex Shapes in the Wooden Boat Workshop},
  shorttitle = {Calculations without Math},
  author = {Martin, Tom and Dillavou, Sam},
  year = {2024},
  month = mar,
  journal = {Journal of Cultural Cognitive Science},
  issn = {2520-1018},
  doi = {10.1007/s41809-024-00140-y},
  urldate = {2024-03-28},
  abstract = {This paper considers a historical boat building practice in light of Runeson's (Scan J Psychol 18:172--179, 1977) concept of `smart instruments', tools that exploit particular features of situated processes to aid their users in complex cognitive operations. The key example here is that of the `spiling stick,' a flexible baton used to determine the two-dimensional shape of board stock that will eventually twist to fit a three-dimensional position on the hull of a ship. The authors illustrate the complexity of the cognitive operation carried out by the `coupled system' (Clark and Chalmers in Analysis 58:7--19, 1998) of boat builder and spiling stick by performing a comparable operation solely with advanced math and physics, tools unavailable for most of the history of wooden boat building. The notion of a `smart instrument' is then discussed in more detail as the authors argue that spiling need not be seen as a mathematical operation supported by material aids, but rather that math and materials provide equal routes for comparable cognitive work.},
  langid = {english},
  keywords = {Boat building,Coupled system,Extended cognition,Smart instrument,Spiling},
  file = {/Users/Sam_1/Zotero/storage/8GHUCZ8B/Martin and Dillavou - 2024 - Calculations without math “Smart instruments” and.pdf},
  preview = {2024Spiling.jpg}
}

@article{pasquet_aqueous_2023,
  title = {Aqueous Foams in Microgravity, Measuring Bubble Sizes},
  author = {Pasquet, Marina and Galvani, Nicolo and Pitois, Olivier and {Cohen-Addad}, Sylvie and H{\"o}hler, Reinhard and Chieco, Anthony T. and Dillavou, Sam and Hanlan, Jesse M. and Durian, Douglas J. and Rio, Emmanuelle and Salonen, Anniina and Langevin, Dominique},
  year = {2023},
  journal = {Comptes Rendus. M{\'e}canique},
  volume = {351},
  number = {S2},
  pages = {1--23},
  issn = {1873-7234},
  doi = {10.5802/crmeca.153},
  urldate = {2023-05-24},
  file = {/Users/Sam_1/Zotero/storage/IND8CMRM/Pasquet et al. - 2023 - Aqueous foams in microgravity, measuring bubble si.pdf},
  abstract = {The paper describes a study of wet foams in microgravity whose bubble size distribution evolves due to diffusive gas exchange. We focus on the comparison between the size of bubbles determined from images of the foam surface and the size of bubbles in the bulk foam, determined from Diffuse Transmission Spectroscopy (DTS). Extracting the bubble size distribution from images of a foam surface is difficult so we have used three different procedures: manual analysis, automatic analysis with a customized Python script and machine learning analysis. Once various pitfalls were identified and taken into account, all the three procedures yield identical results within error bars. DTS only allows the determination of an average bubble radius which is proportional to the photon transport mean free path $l^*$. The relation between the measured diffuse transmitted light intensity and $l^*$ previously derived for slab-shaped samples of infinite lateral extent does not apply to the cuboid geometry of the cells used in the microgravity experiment. A new more general expression of the diffuse intensity transmitted with specific optical boundary conditions has been derived and applied to determine the average bubble radius. The temporal evolution of the average bubble radii deduced from DTS and of the same average radii of the bubbles measured at the sample surface is the same (to a factor probably close to one) throughout the coarsening. Finally, ground experiments were performed to compare bubble size distributions in a bulk wet foam and at its surface at times so short that diffusive gas exchange is insignificant. They were found to be similar, confirming that bubbles seen at the surface are representative of the bulk foam bubbles.},
  arxiv = {2209.03464}
}

@article{pilvelait_influences_2020,
  title = {Influences of Microcontact Shape on the State of a Frictional Interface},
  author = {Pilvelait, Tom and Dillavou, Sam and Rubinstein, Shmuel M.},
  year = {2020},
  month = mar,
  journal = {Physical Review Research},
  volume = {2},
  number = {1},
  pages = {012056},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevResearch.2.012056},
  urldate = {2021-04-21},
  abstract = {The real area of contact of a frictional interface changes rapidly when the normal load is altered, and evolves slowly when the normal load is held constant, aging over time. Traditionally, the total area of contact is considered a proxy for the frictional strength of the interface. Here, we show that the state of a frictional interface is not entirely defined by the total real area of contact but depends on the geometrical nature of that contact as well. We directly visualize an interface between rough elastomers and smooth glass and identify that normal loading and frictional aging evolve the interface differently, even at a single contact level. We introduce a protocol wherein the real area of contact is held constant in time. Under these conditions, the interface is continually evolving; small contacts shrink and large contacts coarsen.},
  file = {/Users/Sam_1/Zotero/storage/PGSD48BR/Pilvelait et al. - 2020 - Influences of microcontact shape on the state of a.pdf;/Users/Sam_1/Zotero/storage/IC5C2DFC/PhysRevResearch.2.html}
}

@article{silverberg_anatomic_2013,
  title = {Anatomic Variation of Depth-Dependent Mechanical Properties in Neonatal Bovine Articular Cartilage},
  author = {Silverberg, Jesse L. and Dillavou, Sam and Bonassar, Lawrence and Cohen, Itai},
  year = {2013},
  journal = {Journal of Orthopaedic Research},
  volume = {31},
  number = {5},
  pages = {686--691},
  issn = {1554-527X},
  doi = {10.1002/jor.22303},
  urldate = {2021-04-21},
  abstract = {Articular cartilage has well known depth-dependent structure and has recently been shown to have similarly non-uniform depth-dependent mechanical properties. Here, we study anatomic variation of the depth-dependent shear modulus and energy dissipation rate in neonatal bovine knees. The regions we specifically focus on are the patellofemoral groove, trochlea, femoral condyle, and tibial plateau. In every sample, we find a highly compliant region within the first 500 {\textmu}m of tissue measured from the articular surface, where the local shear modulus is reduced by up to two orders of magnitude. Comparing measurements taken from different anatomic sites, we find statistically significant differences localized within the first 50 {\textmu}m. Histological images reveal these anatomic variations are associated with differences in collagen density and fiber organization. {\copyright} 2012 Orthopaedic Research Society. Published by Wiley Periodicals, Inc. J Orthop Res 31: 686--691, 2013},
  langid = {english},
  keywords = {articular cartilage,biomechanics,depth-dependent mechanical properties,energy dissipation,shear modulus},
  file = {/Users/Sam_1/Zotero/storage/YEUVRK84/Silverberg et al. - 2013 - Anatomic variation of depth-dependent mechanical p.pdf;/Users/Sam_1/Zotero/storage/693JNHTH/jor.html},
  preview = {2013Cartilage.jpg}
}

@article{steinhardt_seismological_2023,
  title = {Seismological {{Stress Drops}} for {{Confined Ruptures Are Invariant}} to {{Normal Stress}}},
  author = {Steinhardt, Will and Dillavou, Sam and Agajanian, Mary and Rubinstein, Shmuel M. and Brodsky, Emily E.},
  year = {2023},
  month = may,
  journal = {Geophysical Research Letters},
  volume = {50},
  number = {9},
  pages = {e2022GL101366},
  issn = {1944-8007},
  doi = {10.1029/2022GL101366},
  urldate = {2023-05-04},
  abstract = {Seismic moment and rupture length can be combined to infer stress drop, a key parameter for assessing earthquakes. In natural earthquakes, stress drops are largely depth-independent, which is surprising given the expected dependence of frictional stress on normal stresses and hence overburden. We have developed a transparent experimental fault that allows direct observation of thousands of slip events, with ruptures that are fully contained within the fault. Surprisingly, the observed stress drops are largely independent of both the magnitude of normal stress and its heterogeneity, capturing the independence seen in nature. However, we observe larger, normal stress-dependent stress drops when the fault area is reduced, which allows slip events to frequently reach the edge of the interface. We conclude that confined ruptures have normal stress independent stress drops, and thus the depth-independent stress drops of tectonic earthquakes may be a consequence of their confined nature.},
  copyright = {{\copyright} 2023. The Authors. Geophysical Research Letters published by Wiley Periodicals LLC on behalf of American Geophysical Union.},
  langid = {english},
  keywords = {analog model,experiment,friction,stress drop},
  file = {/Users/Sam_1/Zotero/storage/KZT43SPE/Steinhardt et al. - 2023 - Seismological Stress Drops for Confined Ruptures A.pdf;/Users/Sam_1/Zotero/storage/E5TP4KFF/2022GL101366.html}
}

@article{stern_physical_2022,
  title = {Physical Learning beyond the Quasistatic Limit},
  author = {Stern, Menachem and Dillavou, Sam and Miskin, Marc Z. and Durian, Douglas J. and Liu, Andrea J.},
  year = {2022},
  month = may,
  journal = {Physical Review Research},
  volume = {4},
  number = {2},
  pages = {L022037},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevResearch.4.L022037},
  urldate = {2023-01-24},
  abstract = {Physical networks, such as biological neural networks, can learn desired functions without a central processor, using local learning rules in space and time to learn in a fully distributed manner. Learning approaches such as equilibrium propagation, directed aging, and coupled learning similarly exploit local rules to accomplish learning in physical networks such as mechanical, flow, or electrical networks. In contrast to certain natural neural networks, however, such approaches have so far been restricted to the quasistatic limit, where they learn on timescales slow compared to their physical relaxation. This quasistatic constraint slows down learning, limiting the use of these methods as machine learning algorithms, and potentially restricting physical networks that could be used as learning platforms. Here we explore learning in an electrical resistor network that implements coupled learning, both in the laboratory and on the computer, at rates that range from slow to far above the quasistatic limit. We find that up to a critical threshold in the ratio of the learning rate to the physical rate of relaxation, learning speeds up without much change of behavior or error. Beyond the critical threshold, the error exhibits oscillatory dynamics but the networks still learn successfully.},
  file = {/Users/Sam_1/Zotero/storage/RYRN2JAW/Stern et al. - 2022 - Physical learning beyond the quasistatic limit.pdf;/Users/Sam_1/Zotero/storage/RQN8NS4R/PhysRevResearch.4.html},
  arxiv = {2112.11399}
}

@article{stern_training_2024,
  title = {Training Self-Learning Circuits for Power-Efficient Solutions},
  author = {Stern, Menachem and Dillavou, Sam and Jayaraman, Dinesh and Durian, Douglas J. and Liu, Andrea J.},
  year = {2024},
  month = feb,
  journal = {APL Machine Learning},
  volume = {2},
  number = {1},
  pages = {016114},
  issn = {2770-9019},
  doi = {10.1063/5.0181382},
  urldate = {2024-02-28},
  abstract = {As the size and ubiquity of artificial intelligence and computational machine learning models grow, the energy required to train and use them is rapidly becoming economically and environmentally unsustainable. Recent laboratory prototypes of self-learning electronic circuits, such as ``physical learning machines,'' open the door to analog hardware that directly employs physics to learn desired functions from examples at a low energy cost. In this work, we show that this hardware platform allows for an even further reduction in energy consumption by using good initial conditions and a new learning algorithm. Using analytical calculations, simulations, and experiments, we show that a trade-off emerges when learning dynamics attempt to minimize both the error and the power consumption of the solution---greater power reductions can be achieved at the cost of decreasing solution accuracy. Finally, we demonstrate a practical procedure to weigh the relative importance of error and power minimization, improving the power efficiency given a specific tolerance to error.},
  file = {/Users/Sam_1/Zotero/storage/CBRBX5ZD/Training-self-learning-circuits-for-power.html}
}

@article{wycoff_desynchronous_2022,
  title = {Desynchronous Learning in a Physics-Driven Learning Network},
  author = {Wycoff, Jacob and Dillavou, Sam and Stern, Menachem and Liu, Andrea J. and Durian, Douglas J.},
  year = {2022},
  month = apr,
  journal = {The Journal of Chemical Physics},
  volume = {156},
  number = {14},
  pages = {144903},
  publisher = {American Institute of Physics},
  issn = {0021-9606},
  doi = {10.1063/5.0084631},
  urldate = {2022-05-12},
  abstract = {In a neuron network, synapses update individually using local information, allowing for entirely decentralized learning. In contrast, elements in an artificial neural network are typically updated simultaneously using a central processor. Here, we investigate the feasibility and effect of desynchronous learning in a recently introduced decentralized, physics-driven learning network. We show that desynchronizing the learning process does not degrade the performance for a variety of tasks in an idealized simulation. In experiment, desynchronization actually improves the performance by allowing the system to better explore the discretized state space of solutions. We draw an analogy between desynchronization and mini-batching in stochastic gradient descent and show that they have similar effects on the learning process. Desynchronizing the learning process establishes physics-driven learning networks as truly fully distributed learning machines, promoting better performance and scalability in deployment.},
  file = {/Users/Sam_1/Zotero/storage/T6MQZQH6/Wycoff et al. - 2022 - Desynchronous learning in a physics-driven learnin.pdf}
}

@article{zheng_air_2021,
  title = {Air Mediates the Impact of a Compliant Hemisphere on a Rigid Smooth Surface},
  author = {Zheng, Siqi and Dillavou, Sam and Kolinski, John},
  year = {2021},
  journal = {Soft Matter},
  pages = {7},
  langid = {english},
  file = {/Users/Sam_1/Zotero/storage/DBP9M2QY/Zheng - 2021 - Air mediates the impact of a compliant hemisphere .pdf},
  doi = {10.1039/D0SM02163F}
}

@article{srivastava_imitation_2023,
  title = {Beyond the {{Imitation Game}}: {{Quantifying}} and Extrapolating the Capabilities of Language Models},
  shorttitle = {Beyond the {{Imitation Game}}},
  year = {2023},
  author = {Srivastava, Aarohi and ... and Dillavou, Sam and ... and Wu, Ziyi},
  date = {2023-01-19},
  journaltitle = {Transactions on Machine Learning Research},
  issn = {2835-8856},
  url = {https://openreview.net/forum?id=uyTL5Bvosj},
  urldate = {2024-04-16},
  abstract = {Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG- bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood develop- ment, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google- internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit "breakthrough" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.},
  langid = {english},
  file = {/Users/Sam_1/Zotero/storage/83VS4WY8/Srivastava et al. - 2023 - Beyond the Imitation Game Quantifying and extrapo.pdf}
}
