<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Sam Dillavou </title> <meta name="author" content="Sam Dillavou"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%84&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sdillavou.github.io/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Sam</span> Dillavou </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dillavou-480.webp 480w,/assets/img/dillavou-800.webp 800w,/assets/img/dillavou-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/dillavou.jpg?e618e05aca6bedcaa82b72fc4c47b214" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="dillavou.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p><a href="https://maps.app.goo.gl/Wy9kXqFoTzrqpawR8" target="_blank" rel="external nofollow noopener"><i class="fa-solid fa-fw fa-map-marker"></i></a> U. of Pennsylvania</p> <p>Physics &amp; Astronomy</p> <p>Philadelphia, PA 19104</p> <p><a href='mailto:"sdillavou@sas.upenn.edu"' target="_blank"><i class="fa-solid fa-envelope" aria-hidden="true"></i></a> <a href='mailto:"sdillavou@sas.upenn.edu"' target="_blank">Email</a></p> <p><a href="assets/pdf/Academic_CV.pdf" target="_blank" title="CV"><i class="fa-solid fa-fw fa-file"></i></a> <a href="assets/pdf/Academic_CV.pdf" target="_blank" title="CV">CV</a></p> <p><a href="https://scholar.google.com/citations?user=FehGbqYAAAAJ&amp;hl=en" target="_blank" rel="external nofollow noopener"><i class="fa-solid fa-graduation-cap"></i></a> <a href="https://scholar.google.com/citations?user=FehGbqYAAAAJ&amp;hl=en" target="_blank" rel="external nofollow noopener">Google Scholar</a></p> <p><a href="https://www.linkedin.com/in/sam-dillavou/" target="_blank" rel="external nofollow noopener"><i class="fa-brands fa-fw fa-linkedin"></i></a> <a href="https://www.linkedin.com/in/sam-dillavou/" target="_blank" rel="external nofollow noopener">LinkedIn</a></p> <p><a href="https://github.com/sdillavou" target="_blank" rel="external nofollow noopener"><i class="fa-brands fa-fw fa-github"></i></a> <a href="https://github.com/sdillavou" target="_blank" rel="external nofollow noopener">GitHub</a></p> </div> </div> <div class="clearfix"> <p>I am an experimental physicist working as a postdoctoral researcher at the University of Pennsylvania with Douglas Durian and Andrea Liu. I’m interested in a range of topics at the interface of physics, machine learning and robotics, biology, and complex systems.</p> <p>I build <code class="language-plaintext highlighter-rouge">learning metamaterials</code>, analog electronic systems where learning emerges from a collection of self-adjusting elements rather than being enforced by a processor. They share this property with brains and other biological learning systems, but are simple to control, measure, and modify. As a result they also have enormous potential as an energy-efficient machine learning hardware platform, and blur the lines between computers, materials, and biology: how do we think about a ‘computer’ that is divisible like clay?</p> <p>I also use <code class="language-plaintext highlighter-rouge">machine learning</code> as a tool to guide experimental physics research. I focus on systems that have resisted understanding using standard statistical methods, including <code class="language-plaintext highlighter-rouge">granular materials</code> and <code class="language-plaintext highlighter-rouge">frictional interfaces</code>. To make this kind of experimental research easier and more accessible, I develop easy-to-use deep-learning software packages.</p> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2023NonlinearNetwork-480.webp 480w,/assets/img/publication_preview/2023NonlinearNetwork-800.webp 800w,/assets/img/publication_preview/2023NonlinearNetwork-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/2023NonlinearNetwork.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023NonlinearNetwork.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="dillavou_machine_2023" class="col-sm-10"> <div class="title">Machine Learning Without a Processor: Emergent Learning in a Nonlinear Analog Network</div> <div class="author"> <em>Sam Dillavou</em>, Benjamin D. Beyer, <a href="https://amolf.nl/research-groups/learning-machines" rel="external nofollow noopener" target="_blank">Menachem Stern</a>, <a href="https://directory.seas.upenn.edu/marc-miskin/" rel="external nofollow noopener" target="_blank">Marc Z. Miskin</a>, <a href="https://live-sas-physics.pantheon.sas.upenn.edu/people/standing-faculty/andrea-liu" rel="external nofollow noopener" target="_blank">Andrea J. Liu</a>, and <a href="https://live-sas-physics.pantheon.sas.upenn.edu/people/standing-faculty/douglas-durian" rel="external nofollow noopener" target="_blank">Douglas J. Durian</a> </div> <div class="periodical"> </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">APS Awards</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2311.00537" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="/assets/pdf/Generation2Poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>American Physical Society (APS) March Meeting 2023 Best Postdoctoral Poster <br> APS March Meeting 2024 GSNP Best Postdoctoral Talk</p> </div> <div class="abstract hidden"> <p>Standard deep learning algorithms require differentiating large nonlinear networks, a process that is slow and power-hungry. Electronic learning metamaterials offer potentially fast, efficient, and fault-tolerant hardware for analog machine learning, but existing implementations are linear, severely limiting their capabilities. These systems differ significantly from artificial neural networks as well as the brain, so the feasibility and utility of incorporating nonlinear elements have not been explored. Here we introduce a nonlinear learning metamaterial – an analog electronic network made of self-adjusting nonlinear resistive elements based on transistors. We demonstrate that the system learns tasks unachievable in linear systems, including XOR and nonlinear regression, without a computer. We find our nonlinear learning metamaterial reduces modes of training error in order (mean, slope, curvature), similar to spectral bias in artificial neural networks. The circuitry is robust to damage, retrainable in seconds, and performs learned tasks in microseconds while dissipating only picojoules of energy across each transistor. This suggests enormous potential for fast, low-power computing in edge systems like sensors, robotic controllers, and medical devices, as well as manufacturability at scale for performing and studying emergent learning.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2022Demo-480.webp 480w,/assets/img/publication_preview/2022Demo-800.webp 800w,/assets/img/publication_preview/2022Demo-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/2022Demo.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2022Demo.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="dillavou_demonstration_2022" class="col-sm-10"> <div class="title">Demonstration of Decentralized Physics-Driven Learning</div> <div class="author"> <em>Sam Dillavou</em>, <a href="https://amolf.nl/research-groups/learning-machines" rel="external nofollow noopener" target="_blank">Menachem Stern</a>, <a href="https://live-sas-physics.pantheon.sas.upenn.edu/people/standing-faculty/andrea-liu" rel="external nofollow noopener" target="_blank">Andrea J. Liu</a>, and <a href="https://live-sas-physics.pantheon.sas.upenn.edu/people/standing-faculty/douglas-durian" rel="external nofollow noopener" target="_blank">Douglas J. Durian</a> </div> <div class="periodical"> <em>Physical Review Applied</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Herbert Callen Prize</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2108.00275" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="http://doi.org/10.1103/PhysRevApplied.18.014040" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>2023 Herbert B. Callen Memorial Prize from the University of Pennsylvania, “for the first experimental realization of an autonomous network capable of learning complex functionality without need for external memory or processor.” <br> Editor’s Choice, Physical Review Applied</p> </div> <div class="abstract hidden"> <p>In typical artificial neural networks, neurons adjust according to global calculations of a central processor, but in the brain, neurons and synapses self-adjust based on local information. Contrastive learning algorithms have recently been proposed to train physical systems, such as fluidic, mechanical, or electrical networks, to perform machine-learning tasks from local evolution rules. However, to date, such systems have only been implemented in silico due to the engineering challenge of creating elements that autonomously evolve based on their own response to two sets of global boundary conditions. Here, we introduce and implement a physics-driven contrastive learning scheme for a network of variable resistors, using circuitry to locally compare the response of two identical networks subjected to the two different sets of boundary conditions. Using this method, our system effectively trains itself, optimizing its resistance values without the use of a central processor or external information storage. Once the system is trained for a specified allostery, regression, or classification task, the task is subsequently performed rapidly and automatically by the physical imperative to minimize power dissipation in response to the given voltage inputs. We demonstrate that, unlike typical computers, such learning systems are robust to extreme damage (and thus manufacturing defects) due to their decentralized learning. Our twin-network approach is therefore readily scalable to extremely large or nonlinear networks, where its distributed nature will be an enormous advantage; a laboratory network of only 500 edges will already outpace its in silico counterpart.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2018Friction-480.webp 480w,/assets/img/publication_preview/2018Friction-800.webp 800w,/assets/img/publication_preview/2018Friction-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/2018Friction.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2018Friction.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="dillavou_nonmonotonic_2018" class="col-sm-10"> <div class="title">Nonmonotonic Aging and Memory in a Frictional Interface</div> <div class="author"> <em>Sam Dillavou</em>, and <a href="https://phys.huji.ac.il/people/shmuel-m-rubinstein" rel="external nofollow noopener" target="_blank">Shmuel M. Rubinstein</a> </div> <div class="periodical"> <em>Physical Review Letters</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Editor’s Choice</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1103/PhysRevLett.120.224101" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Editor’s Choice, Physical Review Letters</p> </div> <div class="abstract hidden"> <p>We measure the static frictional resistance and the real area of contact between two solid blocks subjected to a normal load. We show that following a two-step change in the normal load the system exhibits nonmonotonic aging and memory effects, two hallmarks of glassy dynamics. These dynamics are strongly influenced by the discrete geometry of the frictional interface, characterized by the attachment and detachment of unique microcontacts. The results are in good agreement with a theoretical model we propose that incorporates this geometry into the framework recently used to describe Kovacs-like relaxation in glasses as well as thermal disordered systems. These results indicate that a frictional interface is a glassy system and strengthen the notion that nonmonotonic relaxation behavior is generic in such systems.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Sam Dillavou. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: July 15, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>