<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Sam Dillavou </title> <meta name="author" content="Sam Dillavou"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%84&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sdillavou.github.io/publications/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Sam</span> Dillavou </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">preprint</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2023NonlinearNetwork-480.webp 480w,/assets/img/publication_preview/2023NonlinearNetwork-800.webp 800w,/assets/img/publication_preview/2023NonlinearNetwork-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/2023NonlinearNetwork.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023NonlinearNetwork.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="dillavou_machine_2023" class="col-sm-10"> <div class="title">Machine Learning Without a Processor: Emergent Learning in a Nonlinear Electronic Metamaterial</div> <div class="author"> <em>Sam Dillavou</em>, Benjamin D. Beyer , Menachem Stern , Marc Z. Miskin , Andrea J. Liu , and Douglas J. Durian </div> <div class="periodical"> Nov 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2311.00537" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>Standard deep learning algorithms require differentiating large nonlinear networks, a process that is slow and power-hungry. Electronic learning metamaterials offer potentially fast, efficient, and fault-tolerant hardware for analog machine learning, but existing implementations are linear, severely limiting their capabilities. These systems differ significantly from artificial neural networks as well as the brain, so the feasibility and utility of incorporating nonlinear elements have not been explored. Here we introduce a nonlinear learning metamaterial – an analog electronic network made of self-adjusting nonlinear resistive elements based on transistors. We demonstrate that the system learns tasks unachievable in linear systems, including XOR and nonlinear regression, without a computer. We find our nonlinear learning metamaterial reduces modes of training error in order (mean, slope, curvature), similar to spectral bias in artificial neural networks. The circuitry is robust to damage, retrainable in seconds, and performs learned tasks in microseconds while dissipating only picojoules of energy across each transistor. This suggests enormous potential for fast, low-power computing in edge systems like sensors, robotic controllers, and medical devices, as well as manufacturability at scale for performing and studying emergent learning.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="dillavou_bellybutton_2023" class="col-sm-10"> <div class="title">Bellybutton: Accessible and Customizable Deep-Learning Image Segmentation</div> <div class="author"> <em>Sam Dillavou</em>, Jesse M. Hanlan , Anthony T. Chieco , Hongyi Xiao , Sage Fulco , Kevin T. Turner , and Douglas J. Durian </div> <div class="periodical"> Aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2309.00058" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>The conversion of raw images into quantifiable data can be a major hurdle in experimental research, and typically involves identifying region(s) of interest, a process known as segmentation. Machine learning tools for image segmentation are often specific to a set of tasks, such as tracking cells, or require substantial compute or coding knowledge to train and use. Here we introduce an easy-to-use (no coding required), image segmentation method, using a 15-layer convolutional neural network that can be trained on a laptop: Bellybutton. The algorithm trains on user-provided segmentation of example images, but, as we show, just one or even a portion of one training image can be sufficient in some cases. We detail the machine learning method and give three use cases where Bellybutton correctly segments images despite substantial lighting, shape, size, focus, and/or structure variation across the regions(s) of interest. Instructions for easy download and use, with further details and the datasets used in this paper are available at pypi.org/project/Bellybuttonseg.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">Journal Articles</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="martin_calculations_2024" class="col-sm-10"> <div class="title">Calculations without Math: “Smart Instruments” and the Transposition of Complex Shapes in the Wooden Boat Workshop</div> <div class="author"> Tom Martin , and <em>Sam Dillavou</em> </div> <div class="periodical"> <em>Journal of Cultural Cognitive Science</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1007/s41809-024-00140-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>This paper considers a historical boat building practice in light of Runeson’s (Scan J Psychol 18:172–179, 1977) concept of ‘smart instruments’, tools that exploit particular features of situated processes to aid their users in complex cognitive operations. The key example here is that of the ‘spiling stick,’ a flexible baton used to determine the two-dimensional shape of board stock that will eventually twist to fit a three-dimensional position on the hull of a ship. The authors illustrate the complexity of the cognitive operation carried out by the ‘coupled system’ (Clark and Chalmers in Analysis 58:7–19, 1998) of boat builder and spiling stick by performing a comparable operation solely with advanced math and physics, tools unavailable for most of the history of wooden boat building. The notion of a ‘smart instrument’ is then discussed in more detail as the authors argue that spiling need not be seen as a mathematical operation supported by material aids, but rather that math and materials provide equal routes for comparable cognitive work.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="stern_training_2024" class="col-sm-10"> <div class="title">Training Self-Learning Circuits for Power-Efficient Solutions</div> <div class="author"> Menachem Stern , <em>Sam Dillavou</em>, Dinesh Jayaraman , Douglas J. Durian , and Andrea J. Liu </div> <div class="periodical"> <em>APL Machine Learning</em>, Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1063/5.0181382" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>As the size and ubiquity of artificial intelligence and computational machine learning models grow, the energy required to train and use them is rapidly becoming economically and environmentally unsustainable. Recent laboratory prototypes of self-learning electronic circuits, such as “physical learning machines,” open the door to analog hardware that directly employs physics to learn desired functions from examples at a low energy cost. In this work, we show that this hardware platform allows for an even further reduction in energy consumption by using good initial conditions and a new learning algorithm. Using analytical calculations, simulations, and experiments, we show that a trade-off emerges when learning dynamics attempt to minimize both the error and the power consumption of the solution—greater power reductions can be achieved at the cost of decreasing solution accuracy. Finally, we demonstrate a practical procedure to weigh the relative importance of error and power minimization, improving the power efficiency given a specific tolerance to error.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="pasquet_aqueous_2023" class="col-sm-10"> <div class="title">Aqueous Foams in Microgravity, Measuring Bubble Sizes</div> <div class="author"> Marina Pasquet , Nicolo Galvani , Olivier Pitois , Sylvie Cohen-Addad , Reinhard Höhler , Anthony T. Chieco , <em>Sam Dillavou</em>, Jesse M. Hanlan , Douglas J. Durian , Emmanuelle Rio , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Anniina Salonen, Dominique Langevin' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Comptes Rendus. Mécanique</em>, Feb 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="http://doi.org/10.5802/crmeca.153" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="steinhardt_seismological_2023" class="col-sm-10"> <div class="title">Seismological Stress Drops for Confined Ruptures Are Invariant to Normal Stress</div> <div class="author"> Will Steinhardt , <em>Sam Dillavou</em>, Mary Agajanian , Shmuel M. Rubinstein , and Emily E. Brodsky </div> <div class="periodical"> <em>Geophysical Research Letters</em>, Feb 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1029/2022GL101366" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>Seismic moment and rupture length can be combined to infer stress drop, a key parameter for assessing earthquakes. In natural earthquakes, stress drops are largely depth-independent, which is surprising given the expected dependence of frictional stress on normal stresses and hence overburden. We have developed a transparent experimental fault that allows direct observation of thousands of slip events, with ruptures that are fully contained within the fault. Surprisingly, the observed stress drops are largely independent of both the magnitude of normal stress and its heterogeneity, capturing the independence seen in nature. However, we observe larger, normal stress-dependent stress drops when the fault area is reduced, which allows slip events to frequently reach the edge of the interface. We conclude that confined ruptures have normal stress independent stress drops, and thus the depth-independent stress drops of tectonic earthquakes may be a consequence of their confined nature.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="dillavou_quality_2022" class="col-sm-10"> <div class="title">Beyond Quality and Quantity: Spatial Distribution of Contact Encodes Frictional Strength</div> <div class="author"> <em>Sam Dillavou</em>, Yohai Bar-Sinai , Michael P. Brenner , and Shmuel M. Rubinstein </div> <div class="periodical"> <em>Physical Review E</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="http://doi.org/10.1103/PhysRevE.106.L033001" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="dillavou_demonstration_2022" class="col-sm-10"> <div class="title">Demonstration of Decentralized Physics-Driven Learning</div> <div class="author"> <em>Sam Dillavou</em>, Menachem Stern , Andrea J. Liu , and Douglas J. Durian </div> <div class="periodical"> <em>Physical Review Applied</em>, Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2108.00275" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="http://doi.org/10.1103/PhysRevApplied.18.014040" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>In typical artificial neural networks, neurons adjust according to global calculations of a central processor, but in the brain, neurons and synapses self-adjust based on local information. Contrastive learning algorithms have recently been proposed to train physical systems, such as fluidic, mechanical, or electrical networks, to perform machine-learning tasks from local evolution rules. However, to date, such systems have only been implemented in silico due to the engineering challenge of creating elements that autonomously evolve based on their own response to two sets of global boundary conditions. Here, we introduce and implement a physics-driven contrastive learning scheme for a network of variable resistors, using circuitry to locally compare the response of two identical networks subjected to the two different sets of boundary conditions. Using this method, our system effectively trains itself, optimizing its resistance values without the use of a central processor or external information storage. Once the system is trained for a specified allostery, regression, or classification task, the task is subsequently performed rapidly and automatically by the physical imperative to minimize power dissipation in response to the given voltage inputs. We demonstrate that, unlike typical computers, such learning systems are robust to extreme damage (and thus manufacturing defects) due to their decentralized learning. Our twin-network approach is therefore readily scalable to extremely large or nonlinear networks, where its distributed nature will be an enormous advantage; a laboratory network of only 500 edges will already outpace its in silico counterpart.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="stern_physical_2022" class="col-sm-10"> <div class="title">Physical Learning beyond the Quasistatic Limit</div> <div class="author"> Menachem Stern , <em>Sam Dillavou</em>, Marc Z. Miskin , Douglas J. Durian , and Andrea J. Liu </div> <div class="periodical"> <em>Physical Review Research</em>, May 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1103/PhysRevResearch.4.L022037" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>Physical networks, such as biological neural networks, can learn desired functions without a central processor, using local learning rules in space and time to learn in a fully distributed manner. Learning approaches such as equilibrium propagation, directed aging, and coupled learning similarly exploit local rules to accomplish learning in physical networks such as mechanical, flow, or electrical networks. In contrast to certain natural neural networks, however, such approaches have so far been restricted to the quasistatic limit, where they learn on timescales slow compared to their physical relaxation. This quasistatic constraint slows down learning, limiting the use of these methods as machine learning algorithms, and potentially restricting physical networks that could be used as learning platforms. Here we explore learning in an electrical resistor network that implements coupled learning, both in the laboratory and on the computer, at rates that range from slow to far above the quasistatic limit. We find that up to a critical threshold in the ratio of the learning rate to the physical rate of relaxation, learning speeds up without much change of behavior or error. Beyond the critical threshold, the error exhibits oscillatory dynamics but the networks still learn successfully.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="wycoff_desynchronous_2022" class="col-sm-10"> <div class="title">Desynchronous Learning in a Physics-Driven Learning Network</div> <div class="author"> J. F. Wycoff , S. Dillavou , M. Stern , A. J. Liu , and D. J. Durian </div> <div class="periodical"> <em>The Journal of Chemical Physics</em>, Apr 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1063/5.0084631" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>In a neuron network, synapses update individually using local information, allowing for entirely decentralized learning. In contrast, elements in an artificial neural network are typically updated simultaneously using a central processor. Here, we investigate the feasibility and effect of desynchronous learning in a recently introduced decentralized, physics-driven learning network. We show that desynchronizing the learning process does not degrade the performance for a variety of tasks in an idealized simulation. In experiment, desynchronization actually improves the performance by allowing the system to better explore the discretized state space of solutions. We draw an analogy between desynchronization and mini-batching in stochastic gradient descent and show that they have similar effects on the learning process. Desynchronizing the learning process establishes physics-driven learning networks as truly fully distributed learning machines, promoting better performance and scalability in deployment.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="durian_spatters_2022" class="col-sm-10"> <div class="title">Spatters and Spills: Spreading Dynamics for Partially Wetting Droplets</div> <div class="author"> Sylvia C. L. Durian , <em>Sam Dillavou</em>, Kwame Markin , Adrian Portales , Bryan O. Torres Maldonado , William T. M. Irvine , Paulo E. Arratia , and Douglas J. Durian </div> <div class="periodical"> <em>Physics of Fluids</em>, Jan 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1063/5.0077461" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>We present a solvable model inspired by dimensional analysis for the time-dependent spreading of droplets that partially wet a substrate, where the spreading eventually stops and the contact angle reaches a nonzero equilibrium value. We separately consider small droplets driven by capillarity and large droplets driven by gravity. To explore both regimes, we first measure the equilibrium radius vs a comprehensive range of droplet volumes for four household fluids, and we compare the results with predictions based on minimizing the sum of gravitational and interfacial energies. The agreement is good and gives a reliable measurement of an equilibrium contact angle that is consistent in both small and large droplet regimes. Next, we use energy considerations to develop equations of motion for the time dependence of the spreading, in both regimes, where the driving forces are balanced against viscous drag in the bulk of the droplet and by friction at the moving contact line. Our approach leads to explicit prediction of the functional form of the spreading dynamics. It successfully describes prior data for a small capillary-driven droplet, and it fits well to new data we obtain for large gravity-driven droplets with a wide range of volumes. While our prediction for the dynamics of small capillary-driven droplets assumes the case of thin nearly wetting droplets, with a small contact angle, this restriction is not otherwise invoked.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="zheng_air_2021" class="col-sm-10"> <div class="title">Air Mediates the Impact of a Compliant Hemisphere on a Rigid Smooth Surface</div> <div class="author"> Siqi Zheng , <em>Sam Dillavou</em>, and John Kolinski </div> <div class="periodical"> <em>Soft Matter</em>, Jan 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="pilvelait_influences_2020" class="col-sm-10"> <div class="title">Influences of Microcontact Shape on the State of a Frictional Interface</div> <div class="author"> Tom Pilvelait , <em>Sam Dillavou</em>, and Shmuel M. Rubinstein </div> <div class="periodical"> <em>Physical Review Research</em>, Mar 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1103/PhysRevResearch.2.012056" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>The real area of contact of a frictional interface changes rapidly when the normal load is altered, and evolves slowly when the normal load is held constant, aging over time. Traditionally, the total area of contact is considered a proxy for the frictional strength of the interface. Here, we show that the state of a frictional interface is not entirely defined by the total real area of contact but depends on the geometrical nature of that contact as well. We directly visualize an interface between rough elastomers and smooth glass and identify that normal loading and frictional aging evolve the interface differently, even at a single contact level. We introduce a protocol wherein the real area of contact is held constant in time. Under these conditions, the interface is continually evolving; small contacts shrink and large contacts coarsen.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="dillavou_shear_2020" class="col-sm-10"> <div class="title">Shear Controls Frictional Aging by Erasing Memory</div> <div class="author"> <em>Sam Dillavou</em>, and Shmuel M. Rubinstein </div> <div class="periodical"> <em>Physical Review Letters</em>, Feb 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1103/PhysRevLett.124.085502" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>We simultaneously measure the static friction and the real area of contact between two solid bodies. These quantities are traditionally considered equivalent, and under static conditions both increase logarithmically in time, a phenomenon coined aging. Here we show that the frictional aging rate is determined by the combination of the aging rate of the real area of contact and two memory-erasure effects that occur when shear is changed (e.g., to measure static friction.) The application of a static shear load accelerates frictional aging while the aging rate of the real area of contact is unaffected. Moreover, a negative static shear—pulling instead of pushing—slows frictional aging, but similarly does not affect the aging of contacts. The origin of this shear effect on aging is geometrical. When shear load is increased, minute relative tilts between the two blocks prematurely erase interfacial memory prior to sliding, negating the effect of aging. Modifying the loading point of the interface eliminates these tilts and as a result frictional aging rate becomes insensitive to shear. We also identify a secondary memory-erasure effect that remains even when all tilts are eliminated and show that this effect can be leveraged to accelerate aging by cycling between two static shear loads.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="dillavou_virtual_2019" class="col-sm-10"> <div class="title">The Virtual Frame Technique: Ultrafast Imaging with Any Camera</div> <div class="author"> S. Dillavou , S. M. Rubinstein , and J. M. Kolinski </div> <div class="periodical"> <em>Optics Express</em>, Mar 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1364/OE.27.008112" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>Many phenomena of interest in nature and industry occur rapidly and are difficult and cost-prohibitive to visualize properly without specialized cameras. Here we describe in detail the virtual frame technique (VFT), a simple, useful, and accessible mode of imaging that increases the frame acquisition rate of any camera by several orders of magnitude by leveraging its dynamic range. The VFT is a powerful tool for capturing rapid phenomena where the dynamics facilitate a transition between two states, and are thus binary. The advantages of the VFT are demonstrated by examining such dynamics in five physical processes at unprecedented rates and spatial resolution: fracture of an elastic solid, wetting of a solid surface, rapid fingerprint reading, peeling of adhesive tape, and impact of an elastic hemisphere on a hard surface. We show that the performance of the VFT exceeds that of any commercial high-speed camera not only in rate of imaging but also in field of view, achieving a 65MHz frame rate at 4MPx resolution. Finally, we discuss the performance of the VFT with several commercially available conventional and high-speed cameras. In principle, modern cell phones can achieve imaging rates of over a million frames per second using the VFT.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="dillavou_nonmonotonic_2018" class="col-sm-10"> <div class="title">Nonmonotonic Aging and Memory in a Frictional Interface</div> <div class="author"> <em>Sam Dillavou</em>, and Shmuel M. Rubinstein </div> <div class="periodical"> <em>Physical Review Letters</em>, Jun 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1103/PhysRevLett.120.224101" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>We measure the static frictional resistance and the real area of contact between two solid blocks subjected to a normal load. We show that following a two-step change in the normal load the system exhibits nonmonotonic aging and memory effects, two hallmarks of glassy dynamics. These dynamics are strongly influenced by the discrete geometry of the frictional interface, characterized by the attachment and detachment of unique microcontacts. The results are in good agreement with a theoretical model we propose that incorporates this geometry into the framework recently used to describe Kovacs-like relaxation in glasses as well as thermal disordered systems. These results indicate that a frictional interface is a glassy system and strengthen the notion that nonmonotonic relaxation behavior is generic in such systems.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2013Cartilage-480.webp 480w,/assets/img/publication_preview/2013Cartilage-800.webp 800w,/assets/img/publication_preview/2013Cartilage-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/2013Cartilage.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2013Cartilage.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="silverberg_anatomic_2013" class="col-sm-10"> <div class="title">Anatomic Variation of Depth-Dependent Mechanical Properties in Neonatal Bovine Articular Cartilage</div> <div class="author"> Jesse L. Silverberg , <em>Sam Dillavou</em>, Lawrence Bonassar , and Itai Cohen </div> <div class="periodical"> <em>Journal of Orthopaedic Research</em>, Jun 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://doi.org/10.1002/jor.22303" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">LINK</a> </div> <div class="abstract hidden"> <p>Articular cartilage has well known depth-dependent structure and has recently been shown to have similarly non-uniform depth-dependent mechanical properties. Here, we study anatomic variation of the depth-dependent shear modulus and energy dissipation rate in neonatal bovine knees. The regions we specifically focus on are the patellofemoral groove, trochlea, femoral condyle, and tibial plateau. In every sample, we find a highly compliant region within the first 500 \textmum of tissue measured from the articular surface, where the local shear modulus is reduced by up to two orders of magnitude. Comparing measurements taken from different anatomic sites, we find statistically significant differences localized within the first 50 \textmum. Histological images reveal these anatomic variations are associated with differences in collagen density and fiber organization. \copyright 2012 Orthopaedic Research Society. Published by Wiley Periodicals, Inc. J Orthop Res 31: 686–691, 2013</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">Conference Articles</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2023Classification-480.webp 480w,/assets/img/publication_preview/2023Classification-800.webp 800w,/assets/img/publication_preview/2023Classification-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/2023Classification.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023Classification.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="dillavou_nonlinear_2023" class="col-sm-10"> <div class="title">Nonlinear Classification Without a Processor</div> <div class="author"> <em>Sam Dillavou</em>, Benjamin Beyer , Menachem Stern , Marc Miskin , Andrea Liu , and Douglas Durian </div> <div class="periodical"> <em>In NeurIPS Workshop Machine Learning with New Compute Paradigms</em> , Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/NonlinearClassificationWithoutAProcessor.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Computers, as well as most neuromorphic hardware systems, use central processing and top-down algorithmic control to train for machine learning tasks. In contrast, brains are ensembles of 100 billion neurons working in tandem, giving them tremendous advantages in power efficiency and speed. Many physical systems ‘learn’ through history dependence, but training a physical system to perform arbitrary nonlinear tasks without a processor has not been possible. Here we demonstrate the successful implementation of such a system - a learning meta-material. This nonlinear analog circuit is comprised of identical copies of a single simple element, each following the same local update rule. By applying voltages to our system (inputs), inference is performed by physics in microseconds. When labels are properly enforced (also via voltages), the system’s internal state evolves in time, approximating gradient descent. Our system {}textit{learns on its own}; it requires no processor. Once trained, it performs inference passively, requiring approximately 100~{}mu\W of total power dissipation across its edges. We demonstrate the flexibility and power efficiency of our system by solving nonlinear 2D classification tasks. Learning meta-materials have immense potential as fast, efficient, robust learning systems for edge computing, from smart sensors to medical devices to robotic control.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="dillavou_circuits_2023" class="col-sm-10"> <div class="title">Circuits That Train Themselves: Decentralized, Physics-Driven Learning</div> <div class="author"> <em>Sam Dillavou</em>, Benjamin Beyer , Menachem Stern , Marc Z. Miskin , Andrea J. Liu , and Douglas J. Durian </div> <div class="periodical"> <em>In AI and Optical Data Sciences IV</em> , Mar 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>In typical artificial neural networks, neurons adjust according to global calculations of a central processor, but in the brain neurons and synapses self-adjust based on local information. A man-made self-adjusting (distributed) system capable of performing machine-learning problems would have substantial scaling advantages over typical computational neural networks, in power consumption, speed, and robustness to damage. Furthermore, such a system would allow us to study physical learning without the added complexity of biology. Here we unveil the second-generation design of such a system – a transistor-based self-adjusting analog network that trains itself to perform a wide variety of tasks. Here we demonstrate basic features of the system, including the ability to monitor all internal states. This platform is already faster than a simulation of itself, and is thus an exciting platform for the investigation of physical learning.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Sam Dillavou. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: April 15, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>